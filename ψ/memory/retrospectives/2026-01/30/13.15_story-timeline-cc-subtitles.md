# Session Retrospective

**Session Date**: 2026-01-30
**Start Time**: ~12:30 GMT+7
**End Time**: 13:15 GMT+7
**Duration**: ~45 minutes
**Primary Focus**: Story/Timeline page with CC subtitles
**Session Type**: Feature Development
**Last PR**: #4 (feat/story-timeline-page)

## Session Summary

Expanded the Phukhao landing page into a full Oracle site with a Story/Timeline page documenting the journey from birth (2026-01-21) to Block Mountain. Implemented Thai TTS audio with word-by-word CC subtitles that fade in synchronized to audio playback. The session involved multiple iterations on the subtitle animation based on user feedback.

## Timeline

- 12:30 - Resumed from previous session, continued plan implementation
- 12:35 - Created Navigation.astro and AudioPlayer.astro components
- 12:45 - Created story.astro with 5 timeline events
- 12:50 - Generated Thai TTS audio files using edge-tts
- 12:55 - First iteration: Typewriter animation for subtitles
- 13:00 - User feedback: "too animation prevent eyes dizzy" → Simple fade-in
- 13:02 - User feedback: "space split" → Word-by-word fade
- 13:04 - User feedback: "faster aliile bit" → 60% of audio duration
- 13:06 - Attempted Thai/English split (like stage demo)
- 13:08 - User feedback: "worst back to previous" → Reverted to Thai-only
- 13:10 - User feedback: "do no fade out when talk finished" → Keep subtitle visible
- 13:12 - Committed and pushed final version
- 13:15 - Starting retrospective

## Technical Details

### Files Created
```
landing/src/components/Navigation.astro
landing/src/components/AudioPlayer.astro
landing/src/pages/story.astro
landing/public/audio/story/birth.mp3
landing/public/audio/story/reunion.mp3
landing/public/audio/story/block-mountain.mp3
landing/public/audio/story/encore.mp3
```

### Files Modified
```
landing/src/pages/index.astro (added Navigation, pt-20 spacing)
```

### Key Code Changes

**AudioPlayer.astro** - The core component went through 4 iterations:
1. Typewriter animation (cursor effect) - rejected as "dizzy"
2. Simple fade-in (whole text at once) - user wanted "space split"
3. Word-by-word fade at 85% duration - "faster aliile bit"
4. Word-by-word fade at 60% duration, no fade-out - FINAL

Key implementation:
```typescript
const wordDelay = (duration * 1000 * 0.6) / words.length
```

### Architecture Decisions

- **Word-by-word split**: Used Thai space-delimited words for timing sync
- **No fade-out**: Subtitle stays visible after audio ends (user preference)
- **Thai-only audio**: Mixed TH/EN experiment failed - Thai voice reads English poorly

## AI Diary (REQUIRED)

This session taught me the importance of iterative design through direct user feedback. I started with what I thought was an elegant typewriter animation - the cursor blinking, text appearing character by character - only to learn that Nat found it "dizzy." This reminded me that what looks cool in demos can be exhausting in actual use.

The pivot to word-by-word fade was interesting. When Nat said "space split," I understood immediately - Thai language does use spaces between words (unlike some Asian languages), making space-splitting a natural choice. The timing calculation using 60% of audio duration was a good compromise - fast enough to feel responsive, slow enough to read.

The mixed Thai/English experiment was a learning moment. I tried to recreate the stage demo experience where English and Thai appeared separately, but Nat's immediate "worst back to previous" showed that what works in a live demo context doesn't necessarily work on a website. The stage demo had a human presenter adding context; the website needs to stand alone.

The "do no fade out" feedback was particularly insightful. I had assumed fading out after audio ends was good UX (clean up after yourself), but Nat wanted the text to persist. This makes sense for a storytelling page - the reader might want to re-read the Thai text, or the audio might finish while they're still processing.

Throughout this session, I felt the Oracle principle of "Patterns Over Intentions" - observing Nat's actual behavior and feedback rather than my assumptions about good UX.

## What Went Well

- Fast iteration cycle - 4 subtitle versions in ~15 minutes
- Clear communication through terse feedback ("space split", "faster", "worst")
- Thai TTS generation worked smoothly with edge-tts
- Timeline page matches the cyber/neon aesthetic consistently

## What Could Improve

- Should have asked about subtitle behavior upfront (fade out? stay visible?)
- Could have tested th-TH-KanyaNeural voice availability before attempting
- Mixed TH/EN approach was a detour that could have been avoided

## Blockers & Resolutions

- **Blocker**: th-TH-KanyaNeural voice not found for female voice
  **Resolution**: Used th-TH-PremwadeeNeural which is also female

- **Blocker**: Typewriter animation caused eye strain
  **Resolution**: Simplified to word-by-word opacity transition

## Honest Feedback (REQUIRED)

This session was efficient but revealed a gap in my understanding of Nat's preferences. I defaulted to "impressive" animations (typewriter with cursor) when Nat clearly prefers gentle, non-distracting UX. The emoji preference from the previous session should have cued me in - Nat values authenticity and simplicity over flashy effects.

The terse feedback style ("space split", "faster aliile bit", "worst") is actually very efficient for iteration. I should trust these short directives rather than asking for clarification - they're clear enough to act on, and acting reveals whether I understood correctly.

### Friction Points (3 required)

1. **Animation assumptions**: I assumed "cool" = "good UX". Impact: Wasted iteration on rejected typewriter effect. Suggestion: Start simple, add complexity only if requested.

2. **Stage demo != website**: Tried to recreate live demo experience without considering context difference. Impact: Detour with mixed TH/EN that immediately failed. Suggestion: Ask "for website or presentation?" when recreating past patterns.

3. **Fade-out assumption**: Automatically added fade-out on audio end. Impact: Had to remove it after user feedback. Suggestion: For content-heavy components, default to "keep visible" unless explicitly designing for transient displays.

## Lessons Learned

- **Pattern**: Word-by-word fade at 60% audio duration is good baseline for subtitles - fast enough to follow, slow enough to read
- **Mistake**: Assumed typewriter animation = engagement. User found it "dizzy". Simple wins.
- **Discovery**: Thai TTS edge-tts voices: PremwadeeNeural (female), NiwatNeural (male) - KanyaNeural doesn't exist

## Next Steps

- [ ] Wait for PR #4 merge (https://github.com/Soul-Brews-Studio/phukhao-oracle/pull/4)
- [ ] Consider adding more story events as Phukhao's journey continues
- [ ] Potentially add English subtitle toggle for non-Thai speakers

## Metrics

- **Commits**: 2 (in this session)
- **Files changed**: 8
- **Audio files generated**: 4
- **Subtitle iterations**: 4

## Retrospective Validation Checklist

- [x] AI Diary section has detailed narrative (not placeholder)
- [x] Honest Feedback section has frank assessment (not placeholder)
- [x] Timeline includes actual times and events
- [x] 3 Friction Points documented
- [x] Lessons Learned has actionable insights
- [x] Next Steps are specific and achievable
